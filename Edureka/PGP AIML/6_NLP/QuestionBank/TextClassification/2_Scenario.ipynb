{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8f4eae4",
   "metadata": {},
   "source": [
    "### Categorizing Tweets Using Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb0f7f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vlekkala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vlekkala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ade0e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget -O scocialmedia_relevant_cols.csv https://www.dropbox.com/s/rsdr3419xk9yean/socialmedia_relevant_cols.csv --no-check-certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "699098c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>choose_one</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text choose_one  class_label\n",
       "0                 Just happened a terrible car crash   Relevant            1\n",
       "1  Our Deeds are the Reason of this #earthquake M...   Relevant            1\n",
       "2  Heard about #earthquake is different cities, s...   Relevant            1\n",
       "3  there is a forest fire at spot pond, geese are...   Relevant            1\n",
       "4             Forest fire near La Ronge Sask. Canada   Relevant            1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('socialmedia_relevant_cols.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e42addde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fafd92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text           0\n",
       "choose_one     0\n",
       "class_label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "919496ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6187\n",
       "1    4673\n",
       "2      16\n",
       "Name: class_label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.class_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d868eb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "stop_words = stopwords.words('English')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "484141cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    words = word_tokenize(sentence)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in words \n",
    "             if word not in stop_words \n",
    "              and word not in string.punctuation\n",
    "             and re.match(r'^\\w+$', word)]\n",
    "    return \" \".join(tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10f7fa62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>choose_one</th>\n",
       "      <th>class_label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>happened terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquake may allah forgive u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>heard earthquake different city stay safe ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire spot pond goose fleeing across str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text choose_one  class_label  \\\n",
       "0                 Just happened a terrible car crash   Relevant            1   \n",
       "1  Our Deeds are the Reason of this #earthquake M...   Relevant            1   \n",
       "2  Heard about #earthquake is different cities, s...   Relevant            1   \n",
       "3  there is a forest fire at spot pond, geese are...   Relevant            1   \n",
       "4             Forest fire near La Ronge Sask. Canada   Relevant            1   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0                        happened terrible car crash  \n",
       "1         deed reason earthquake may allah forgive u  \n",
       "2  heard earthquake different city stay safe ever...  \n",
       "3  forest fire spot pond goose fleeing across str...  \n",
       "4              forest fire near la ronge sask canada  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6f8c55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(lowercase=True)\n",
    "model = RandomForestClassifier()\n",
    "X = df['cleaned_text']\n",
    "y = df['class_label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = Pipeline([('tfidf', tfidf), ('model', model)])\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3989cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83      1216\n",
      "           1       0.83      0.69      0.75       957\n",
      "           2       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.80      2176\n",
      "   macro avg       0.54      0.53      0.53      2176\n",
      "weighted avg       0.80      0.80      0.80      2176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e125bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5: Analyze text data\n",
    "# Find the size of vocabulary of the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10971470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('http', 6774),\n",
       " ('fire', 513),\n",
       " ('amp', 510),\n",
       " ('like', 494),\n",
       " ('get', 379),\n",
       " ('new', 327),\n",
       " ('via', 323),\n",
       " ('one', 291),\n",
       " ('u', 290),\n",
       " ('news', 288),\n",
       " ('people', 280),\n",
       " ('2', 237),\n",
       " ('video', 235),\n",
       " ('time', 227),\n",
       " ('would', 226),\n",
       " ('emergency', 224),\n",
       " ('disaster', 222),\n",
       " ('year', 210),\n",
       " ('body', 198),\n",
       " ('police', 196)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete = \" \".join(df['cleaned_text'])\n",
    "words = complete.split()\n",
    "from collections import Counter\n",
    "\n",
    "count_vocab = Counter(words)\n",
    "count_vocab.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b157f94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>choose_one</th>\n",
       "      <th>class_label</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>happened terrible car crash</td>\n",
       "      <td>[happened, terrible, car, crash]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquake may allah forgive u</td>\n",
       "      <td>[deed, reason, earthquake, may, allah, forgive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>heard earthquake different city stay safe ever...</td>\n",
       "      <td>[heard, earthquake, different, city, stay, saf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire spot pond goose fleeing across str...</td>\n",
       "      <td>[forest, fire, spot, pond, goose, fleeing, acr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text choose_one  class_label  \\\n",
       "0                 Just happened a terrible car crash   Relevant            1   \n",
       "1  Our Deeds are the Reason of this #earthquake M...   Relevant            1   \n",
       "2  Heard about #earthquake is different cities, s...   Relevant            1   \n",
       "3  there is a forest fire at spot pond, geese are...   Relevant            1   \n",
       "4             Forest fire near La Ronge Sask. Canada   Relevant            1   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0                        happened terrible car crash   \n",
       "1         deed reason earthquake may allah forgive u   \n",
       "2  heard earthquake different city stay safe ever...   \n",
       "3  forest fire spot pond goose fleeing across str...   \n",
       "4              forest fire near la ronge sask canada   \n",
       "\n",
       "                                              tokens  \n",
       "0                   [happened, terrible, car, crash]  \n",
       "1  [deed, reason, earthquake, may, allah, forgive...  \n",
       "2  [heard, earthquake, different, city, stay, saf...  \n",
       "3  [forest, fire, spot, pond, goose, fleeing, acr...  \n",
       "4      [forest, fire, near, la, ronge, sask, canada]  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'] = df.cleaned_text.str.split()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12118f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question-6: Create word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "421f41a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model_vec_train = Word2Vec(sentences=df['tokens'], size=200, window=5, min_count=5, workers=-1, sg=1)\n",
    "model_vec_train.save('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15cd9c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vec_train['like'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1931309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question-7: Generate features using word embeddings for training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9aad60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_embeddings(sent_token, model=model_vec_train):\n",
    "    vector = [model[word] if word in model else np.zeros(200) for word in sent_token]\n",
    "    l = len(vector)\n",
    "    s = np.sum(vector, axis=0)\n",
    "    avg = s/l\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "216f41ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(data, model=model_vec_train):\n",
    "    embeddings = data.apply(lambda x:get_embeddings(x, model))\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b108837",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['tokens'], df['class_label'], test_size=0.2, random_state=42)\n",
    "\n",
    "embeddings_train = generate_embeddings(X_train)\n",
    "embeddings_test = generate_embeddings(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5cd1009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the output word embeddings as dataframe\n",
    "\n",
    "d = dict()\n",
    "for i in range(200):\n",
    "    l = []\n",
    "    for j in range(8700):\n",
    "        try:\n",
    "            l.append(embeddings_train.values[j][i])\n",
    "        except:\n",
    "            l.append(0)\n",
    "    d[i] = l\n",
    "train = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4fd8eefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = dict()\n",
    "for i in range(200):\n",
    "    l = []\n",
    "    for j in range(2176):\n",
    "        try:\n",
    "            l.append(embeddings_test.values[j][i])\n",
    "        except:\n",
    "            l.append(0)\n",
    "    dic[i] = l\n",
    "    \n",
    "test = pd.DataFrame(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37cabf10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8700, 200)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "84796895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000044</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>-0.000194</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>-0.000815</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>-0.000111</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>-0.000382</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>-0.000294</td>\n",
       "      <td>-0.000333</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>-0.000685</td>\n",
       "      <td>-0.000768</td>\n",
       "      <td>-0.000515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000403</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.000194</td>\n",
       "      <td>-0.000506</td>\n",
       "      <td>-0.000133</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>-0.000418</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>-0.000334</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.000393</td>\n",
       "      <td>-0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000109</td>\n",
       "      <td>-0.000515</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>-0.000752</td>\n",
       "      <td>-0.001054</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>-0.000614</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>-0.000290</td>\n",
       "      <td>-0.000635</td>\n",
       "      <td>-0.000786</td>\n",
       "      <td>-0.000548</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>-0.000426</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>0.000693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>-0.000518</td>\n",
       "      <td>-0.000534</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>-0.000479</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>-0.000274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>-0.000663</td>\n",
       "      <td>-0.000933</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>-0.000297</td>\n",
       "      <td>-0.000523</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.000435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000258</td>\n",
       "      <td>-0.000652</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>-0.001568</td>\n",
       "      <td>-0.000393</td>\n",
       "      <td>-0.000608</td>\n",
       "      <td>-0.000186</td>\n",
       "      <td>-0.000270</td>\n",
       "      <td>-0.000505</td>\n",
       "      <td>-0.000263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>-0.000225</td>\n",
       "      <td>-0.000287</td>\n",
       "      <td>-0.000284</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>-0.000937</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.000805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.000044  0.000258 -0.000194  0.000438  0.000204 -0.000422 -0.000815   \n",
       "1 -0.000005 -0.000403 -0.000071 -0.000194 -0.000506 -0.000133  0.000197   \n",
       "2  0.000109 -0.000515  0.001282  0.000134 -0.000752 -0.001054  0.000074   \n",
       "3 -0.000012  0.000064  0.000403 -0.000411 -0.000518 -0.000534  0.000295   \n",
       "4 -0.000258 -0.000652  0.000225 -0.001568 -0.000393 -0.000608 -0.000186   \n",
       "\n",
       "        7         8         9    ...       190       191       192       193  \\\n",
       "0 -0.000115 -0.000111  0.000314  ...  0.000266 -0.000382  0.000150  0.000373   \n",
       "1  0.000403 -0.000047 -0.000197  ...  0.000030 -0.000418 -0.000172  0.000149   \n",
       "2 -0.000614  0.000186  0.000203  ...  0.000085  0.000609 -0.000290 -0.000635   \n",
       "3 -0.000479 -0.000128 -0.000274  ...  0.000019  0.000381 -0.000663 -0.000933   \n",
       "4 -0.000270 -0.000505 -0.000263  ...  0.001069  0.000285  0.001194 -0.000225   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0 -0.000294 -0.000333 -0.000135 -0.000685 -0.000768 -0.000515  \n",
       "1  0.000050 -0.000334  0.000467  0.000046 -0.000393 -0.000260  \n",
       "2 -0.000786 -0.000548  0.000195 -0.000426 -0.000311  0.000693  \n",
       "3  0.000528 -0.000297 -0.000523 -0.000038  0.001099  0.000435  \n",
       "4 -0.000287 -0.000284  0.000257 -0.000937  0.000930  0.000805  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "737b2c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question-8: Perform K-Fold cross validation for model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8921d4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.7108045977011495(standard deviation: 0.021455801860537926\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "cross_val_sc = cross_val_score(model, train, y_train, scoring='accuracy', cv=kfold)\n",
    "print('acc: {}(standard deviation: {}'.format(cross_val_sc.mean(), cross_val_sc.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1efb740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9844827586206897"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(train, y_train)\n",
    "model.score(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cee50f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
