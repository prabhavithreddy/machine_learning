{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eb2310d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stockholm\n",
      "is\n",
      "the\n",
      "capital\n",
      "of\n",
      "Sweden\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "doc = nlp('Stockholm is the capital of Sweden')\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2d1c9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sweden"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# at a specific point\n",
    "token = doc[-1]\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cac3a31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is the"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Span of doc\n",
    "doc[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc727452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "text ['it', 'costs', '$', '5.00', 'for', 'those', '5', 'apples', '.']\n",
      "punct [False, False, False, False, False, False, False, False, True]\n",
      "alpha [True, True, False, False, True, True, False, True, False]\n"
     ]
    }
   ],
   "source": [
    "# Lexical attributes \n",
    "doc = nlp('it costs $5.00 for those 5 apples.')\n",
    "print('index: ', [token.i for token in doc])\n",
    "print('text', [token.text for token in doc])\n",
    "print('punct', [token.is_punct for token in doc])\n",
    "print('alpha', [token.is_alpha for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a507808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She   She\n",
      "ate   ate\n",
      "the   the\n",
      "pizza   pizza\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"She ate the pizza\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.tag_, token.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f6aeedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Im Streit um die Migranten an der östlichen EU-Außengrenze fehlt es nicht an martialischer Rhetorik in Richtung Belarus. Die Diplomatie kam bisher zu kurz. Das ist die Stunde der OSZE, meint Roman Goncharenko.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# German Text\n",
    "from spacy.lang.de import German\n",
    "\n",
    "nlp = German()\n",
    "doc = nlp(\"Im Streit um die Migranten an der östlichen EU-Außengrenze fehlt es nicht an martialischer Rhetorik in Richtung Belarus. Die Diplomatie kam bisher zu kurz. Das ist die Stunde der OSZE, meint Roman Goncharenko.\")\n",
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1f70f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kangaroos and koalas\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I like kangaroos and koalas in Austrialia\")\n",
    "tree_kang = doc[2:5]\n",
    "print(tree_kang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c983f580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Akasa Air on Tuesday placed an order for 72 Boeing 737 MAX jets, valued at nearly $9 billion at list prices - a deal that could help the US planemaker regain lost ground in one of the world's most promising markets.\")\n",
    "for token in doc:\n",
    "    if token.like_num and doc[token.i - 1].text == '$':\n",
    "        print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af43d833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.2.5\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: spacy>=2.2.2 in c:\\python36_64\\lib\\site-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\python36_64\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\python36_64\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\python36_64\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
      "Requirement already satisfied: setuptools in c:\\python36_64\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (54.2.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\python36_64\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\python36_64\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.26.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\python36_64\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\python36_64\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\python36_64\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\python36_64\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\python36_64\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: thinc==7.4.0 in c:\\python36_64\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\python36_64\\lib\\site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.50.2)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in c:\\python36_64\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python36_64\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python36_64\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\python36_64\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python36_64\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.11.28)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\python36_64\\lib\\site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\python36_64\\lib\\site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.3.1)\n",
      "Building wheels for collected packages: en-core-web-sm\n",
      "  Building wheel for en-core-web-sm (setup.py): started\n",
      "  Building wheel for en-core-web-sm (setup.py): finished with status 'done'\n",
      "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.2.5-py3-none-any.whl size=12011736 sha256=f0bd3fb15b58591facb6bfa4c948ff77f241f5095aaccc95f5245881ea2919c7\n",
      "  Stored in directory: C:\\Users\\vlekkala\\AppData\\Local\\Temp\\1\\pip-ephem-wheel-cache-at2od37_\\wheels\\b5\\94\\56\\596daa677d7e91038cbddfcf32b591d0c915a1b3a3e3d3c79d\n",
      "Successfully built en-core-web-sm\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-2.2.5\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -wisted (c:\\python36_64\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -wisted (c:\\python36_64\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -wisted (c:\\python36_64\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -wisted (c:\\python36_64\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -wisted (c:\\python36_64\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -wisted (c:\\python36_64\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf2ed640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parts of Speech Spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5be34488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She PRON PRP ate\n",
      "ate VERB VBD ate\n",
      "the DET DT pizza\n",
      "pizza NOUN NN ate\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"She ate the pizza\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.tag_, token.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c28a0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It          PRON      nsubj     \n",
      "'s          AUX       ROOT      \n",
      "official    ADJ       attr      \n",
      "that        SCONJ     mark      \n",
      "Apple       PROPN     nsubj     \n",
      "is          AUX       ccomp     \n",
      "the         DET       det       \n",
      "first       ADJ       amod      \n",
      "U.S.        PROPN     nmod      \n",
      "public      ADJ       amod      \n",
      "company     NOUN      attr      \n",
      "to          PART      aux       \n",
      "reach       VERB      relcl     \n",
      "a           DET       det       \n",
      "$           SYM       quantmod  \n",
      "1           NUM       compound  \n",
      "Trillion    NUM       nummod    \n",
      "market      NOUN      compound  \n",
      "value       NOUN      dobj      \n"
     ]
    }
   ],
   "source": [
    "text = \"It's official that Apple is the first U.S. public company to reach a $1 Trillion market value\"\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    token_text = token.text\n",
    "    token_pos = token.pos_\n",
    "    token_dep = token.dep_\n",
    "    print(\"{:<12}{:<10}{:<10}\".format(token_text, token_pos, token_dep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3cf4b0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n"
     ]
    }
   ],
   "source": [
    "text = \"New IPhone X release date leaked as Apple reveals pre-order by mistake\"\n",
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63777ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Companies, agencies, institutions, etc.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('ORG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e158b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
