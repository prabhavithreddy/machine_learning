{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51b5c3ed",
   "metadata": {},
   "source": [
    "# Rule based matching using spacy matcher\n",
    "    Compared with regular expression the matcher works on doc objects instead of only string\n",
    "    We can match on tokens and token attributes\n",
    "    We can write rules that use the models predictions\n",
    "    Example \"duck\" (verb) vs \"duck\" (noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "598bd5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhone X\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "#import the matcher\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Load the model and create nlp object\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# initialize the matcher with shared vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# add pattern\n",
    "pattern = [{'ORTH':'iPhone'}, {'ORTH':'X'}]\n",
    "matcher.add('IPhone', [pattern])\n",
    "\n",
    "#process the text\n",
    "doc = nlp(\"New iPhone X release date has been leaked.\")\n",
    "\n",
    "# call the matcher\n",
    "match = matcher(doc)\n",
    "\n",
    "for match_id, start, end in match:\n",
    "    # match_id - hash value of the pattern\n",
    "    # start - start index of the matched span\n",
    "    # end - end index of the matched span\n",
    "    print(doc[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eccd6676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1882071534088494249 animal\n",
      "1882071534088494249 planet\n"
     ]
    }
   ],
   "source": [
    "# Match the lexical attributes\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pattern = [{'POS':'NOUN'}]\n",
    "\n",
    "matcher.add('Noun', [pattern])\n",
    "\n",
    "doc = nlp('Cat is the cutest animal in the planet.')\n",
    "\n",
    "match  = matcher(doc)\n",
    "\n",
    "for match_id, start, end in match:\n",
    "    print(match_id, doc[start: end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94ec09e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 Fifa World\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"FIFA has won the 2018 Fifa World Cup!\")\n",
    "pattern = [{'IS_DIGIT': True}, {'LOWER': 'fifa'}, {'LOWER': 'world'}]\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('FIFA', [pattern])\n",
    "match = matcher(doc)\n",
    "\n",
    "for match_id, start, end in match:\n",
    "    print(doc[start: end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6ae888a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bought\n",
      "bought a\n",
      "buying\n",
      "buying the\n"
     ]
    }
   ],
   "source": [
    "# match using operators and quantifiers\n",
    "\n",
    "doc = nlp('I bought a smartphone and now I am buying the apps')\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pattern = [{'LEMMA': 'buy'}, {'POS': 'DET', 'OP': '?'}]\n",
    "\n",
    "matcher.add('LEMMA', [pattern])\n",
    "\n",
    "match = matcher(doc)\n",
    "\n",
    "for match_id, start, end in match:\n",
    "    print(doc[start: end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d70ee582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaded\n",
      "downloaded Fortnite\n",
      "downloading\n",
      "download\n",
      "download Winzip\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I downloaded Fortnite on my laptop and can't open the game at all. Help? so when I was downloading\\\n",
    "           Minecraft, I got the Windows version where it is the '.zip' folder and I used the default program to unpack\\\n",
    "           it... do I also need to download Winzip?\")\n",
    "\n",
    "pattern = [{'LEMMA': 'download'}, {'POS': 'PROPN', 'OP':'?'}, {'POS': 'NOUN', 'OP':'?'}]\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('Test', [pattern])\n",
    "match = matcher(doc)\n",
    "\n",
    "for match_id, start, end in match:\n",
    "    print(doc[start: end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38abfe6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beautiful design\n",
      "smart search\n",
      "automatic labels\n",
      "optional voice\n",
      "optional voice responses\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Features of the app include a beautiful design, smart search, automatic labels and optional voice responses.\")\n",
    "# write a pattern for adjective plus one or two nouns\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{'POS':'ADJ'}, {'POS': 'NOUN'}, {'POS': 'NOUN', 'OP':'?'}]\n",
    "matcher.add('Nouns', [pattern])\n",
    "\n",
    "match = matcher(doc)\n",
    "for match_id, start, end in match:\n",
    "    print(doc[start:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ef0360",
   "metadata": {},
   "source": [
    "### Phrase Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01148c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden Retriver\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "\n",
    "pattern = nlp('Golden Retriver')\n",
    "matcher.add('Dog', [pattern])\n",
    "\n",
    "doc = nlp('I have a Golden Retriver')\n",
    "\n",
    "match = matcher(doc)\n",
    "\n",
    "for match_id, start, end in match:\n",
    "    print(doc[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a0197ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTRIES = ['Afghanistan','Albania','Algeria','Andorra','Angola','Antigua and Barbuda','Argentina','Armenia','Australia','Austria','Azerbaijan','Bahamas','Bahrain','Bangladesh','Barbados','Belarus','Belgium','Belize','Benin','Bhutan','Bolivia','Bosnia and Herzegovina','Botswana','Brazil','Brunei','Bulgaria','Burkina Faso','Burundi',\"CÃ´te d'Ivoire\",'Cabo Verde','Cambodia','Cameroon','Canada','Central African Republic','Chad','Chile','China','Colombia','Comoros','Congo (Congo-Brazzaville)','Costa Rica','Croatia','Cuba','Cyprus','Czech Republic','Democratic Republic of the Congo','Denmark','Djibouti','Dominica','Dominican Republic','Ecuador','Egypt','El Salvador','Equatorial Guinea','Eritrea','Estonia','Eswatini (fmr. \"Swaziland\")','Ethiopia','Fiji','Finland','France','Gabon','Gambia','Georgia','Germany','Ghana','Greece','Grenada','Guatemala','Guinea','Guinea-Bissau','Guyana','Haiti','Holy See','Honduras','Hungary','Iceland','India','Indonesia','Iran','Iraq','Ireland','Israel','Italy','Jamaica','Japan','Jordan','Kazakhstan','Kenya','Kiribati','Kuwait','Kyrgyzstan','Laos','Latvia','Lebanon','Lesotho','Liberia','Libya','Liechtenstein','Lithuania','Luxembourg','Madagascar','Malawi','Malaysia','Maldives','Mali','Malta','Marshall Islands','Mauritania','Mauritius','Mexico','Micronesia','Moldova','Monaco','Mongolia','Montenegro','Morocco','Mozambique','Myanmar (formerly Burma)','Namibia','Nauru','Nepal','Netherlands','New Zealand','Nicaragua','Niger','Nigeria','North Korea','North Macedonia','Norway','Oman','Pakistan','Palau','Palestine State','Panama','Papua New Guinea','Paraguay','Peru','Philippines','Poland','Portugal','Qatar','Romania','Russia','Rwanda','Saint Kitts and Nevis','Saint Lucia','Saint Vincent and the Grenadines','Samoa','San Marino','Sao Tome and Principe','Saudi Arabia','Senegal','Serbia','Seychelles','Sierra Leone','Singapore','Slovakia','Slovenia','Solomon Islands','Somalia','South Africa','South Korea','South Sudan','Spain','Sri Lanka','Sudan','Suriname','Sweden','Switzerland','Syria','Tajikistan','Tanzania','Thailand','Timor-Leste','Togo','Tonga','Trinidad and Tobago','Tunisia','Turkey','Turkmenistan','Tuvalu','Uganda','Ukraine','United Arab Emirates','United Kingdom','United States of America','Uruguay','Uzbekistan','Vanuatu','Venezuela','Vietnam','Yemen','Zambia','Zimbabwe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d4d6c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Czech Republic, Russia]\n"
     ]
    }
   ],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "\n",
    "doc = nlp(\"Czech Republic may help Slovaks protect its regime from Russia\")\n",
    "pattern = list(nlp.pipe(COUNTRIES))\n",
    "matcher.add('Country', pattern)\n",
    "\n",
    "match = matcher(doc)\n",
    "print([doc[start:end] for match_id, start, end in match])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9304161f",
   "metadata": {},
   "source": [
    "### Comparing Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d2ca587",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ef1c09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9297710649238541"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_king = nlp('I like King')\n",
    "doc_queen = nlp(\"I like Queen\")\n",
    "\n",
    "doc_king.similarity(doc_queen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4129f109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7687319998878382"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_men = nlp('I like Men')\n",
    "doc_women = nlp(\"I like Women\")\n",
    "\n",
    "doc_men.similarity(doc_women)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "265da698",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.0410e-02, -1.1339e-02,  3.2865e-01, -3.8009e-01, -3.2345e-01,\n",
       "        5.4006e-02,  5.3922e-01,  3.2480e-01,  5.8872e-01,  3.1140e+00,\n",
       "       -3.4070e-01, -3.5357e-01,  1.6412e-01, -1.3405e-01,  2.5613e-01,\n",
       "       -4.5910e-01, -2.9710e-01,  8.7180e-01, -4.5571e-03,  5.2537e-01,\n",
       "       -1.3515e-01, -6.3228e-01, -1.4012e-01, -1.6667e-01, -1.8224e-01,\n",
       "        9.4281e-02,  1.7619e-01,  2.7576e-01,  5.1345e-01,  3.4117e-01,\n",
       "       -3.9954e-01,  6.7538e-01, -1.0417e+00, -5.3799e-02,  2.0235e-01,\n",
       "       -7.4971e-01,  1.7682e-01, -7.2984e-01, -9.5704e-02,  2.9547e-01,\n",
       "       -6.5500e-01, -7.5561e-02,  3.5961e-01, -4.1948e-01,  2.3379e-01,\n",
       "       -3.3119e-01,  8.5873e-02,  1.1059e-01,  2.8848e-01, -2.1663e-02,\n",
       "       -6.8974e-01, -3.8078e-01,  6.3097e-02, -1.9700e-01,  5.2430e-01,\n",
       "        4.2529e-01,  1.1217e-01, -2.3269e-01, -4.3879e-01, -1.0308e-01,\n",
       "       -2.1555e-02, -1.2585e-01, -4.8075e-02,  2.9648e-01, -1.6962e-01,\n",
       "        4.4210e-01,  1.7999e-01,  1.0938e-01, -2.6039e-01,  2.0119e-01,\n",
       "       -8.9665e-02,  1.0716e-01,  5.9712e-01, -3.3036e-03,  5.6617e-01,\n",
       "       -3.1723e-02,  3.5135e-02, -3.6430e-01,  5.9350e-01, -1.6097e-02,\n",
       "       -1.8291e-01, -1.8583e-01,  6.8556e-03,  1.3321e-01,  2.7605e-01,\n",
       "       -2.6041e-01,  1.6848e-01, -1.5484e-01, -6.4728e-01,  1.5859e-01,\n",
       "       -1.2464e-01, -1.7170e-01,  5.4091e-01, -6.9171e-02, -3.6884e-01,\n",
       "       -4.0577e-01, -6.0763e-02, -2.3791e-01, -3.1313e-01, -5.1737e-01,\n",
       "        1.4677e-01,  9.4378e-01,  1.8723e-01,  1.2641e-01, -3.8301e-02,\n",
       "       -7.3311e-01, -4.0987e-01,  2.7184e-01, -6.7626e-02,  4.1054e-01,\n",
       "        7.0251e-01, -7.2515e-01, -4.6958e-01,  1.6841e-01,  4.6450e-02,\n",
       "        4.0476e-01,  2.1200e-01,  6.0767e-02, -2.0332e-02,  2.8963e-01,\n",
       "        3.7794e-01, -3.3812e-01,  8.1681e-03, -3.0403e-02,  2.4966e-01,\n",
       "       -3.1415e-01,  3.1308e-01,  1.6403e-01,  4.2490e-01, -3.9146e-01,\n",
       "        2.3609e-01,  7.3408e-02, -5.4946e-01, -4.5296e-01,  1.7785e-01,\n",
       "       -7.0573e-02,  6.3894e-01, -5.0821e-01, -1.4771e-02,  1.3963e-01,\n",
       "       -1.8432e+00,  1.7870e-02,  3.1228e-01, -9.3060e-02,  3.1424e-01,\n",
       "       -4.4649e-02,  5.9720e-01, -1.5550e-01, -6.7625e-01,  4.0804e-01,\n",
       "       -5.5911e-01, -6.6267e-01, -2.7924e-01, -2.5046e-01, -2.2352e-01,\n",
       "        5.5153e-02, -4.5620e-01, -4.5445e-01,  5.2646e-02,  1.9915e-01,\n",
       "       -8.6523e-02, -5.7200e-01, -5.7632e-02, -2.1888e-01,  1.0374e-01,\n",
       "       -3.0807e-01,  1.1125e-01, -7.5091e-02, -3.8025e-01,  4.0831e-01,\n",
       "       -6.5341e-01,  2.5767e-01,  9.7963e-02,  3.6073e-01, -3.4259e-01,\n",
       "       -2.0379e-01, -3.3027e-02,  1.5962e-01,  4.1355e-01, -1.3193e-01,\n",
       "       -2.5554e-01,  3.0905e-01, -1.4001e-01, -1.6774e-01, -4.0606e-01,\n",
       "        4.6398e-01, -5.9510e-02,  3.3628e-01,  4.9223e-01, -9.8084e-02,\n",
       "        1.9019e-01, -2.7283e-01,  2.1355e-01,  1.2849e-01,  1.9033e-01,\n",
       "        4.2332e-02,  1.4967e-01, -8.8655e-01, -1.5901e-01, -5.1046e-02,\n",
       "        6.7921e-01,  1.1217e-01,  8.7189e-02, -2.2116e-01, -2.4555e-01,\n",
       "        6.7818e-02, -3.0077e-01, -4.5009e-01, -5.1419e-01,  1.6473e-01,\n",
       "        2.9655e-01, -1.1337e-01, -2.5274e-01, -3.9675e-01,  6.1493e-02,\n",
       "       -7.6067e-01, -9.0968e-02, -1.2139e-01,  4.9209e-02, -3.2084e-01,\n",
       "       -4.8045e-02,  1.3558e-01, -3.6420e-01, -4.6124e-03, -3.7027e-01,\n",
       "       -1.5157e-01, -3.2520e-01,  2.8758e-01,  9.9263e-02,  1.7552e-01,\n",
       "       -1.1226e-03,  1.5635e-02, -2.3652e-01, -5.9548e-02, -1.5598e-01,\n",
       "       -9.6459e-02, -5.6244e-02,  1.3922e-01,  1.0748e-01,  3.0046e-01,\n",
       "       -1.3502e-01,  8.2462e-02, -1.0162e-01, -4.1902e-01,  2.4997e-01,\n",
       "        1.0397e-01, -4.0739e-01, -1.1884e-01, -2.2796e-01,  6.8966e-01,\n",
       "        1.1014e-01,  4.6644e-01,  3.3598e-01, -1.8136e-01,  5.8534e-02,\n",
       "        4.3551e-01,  5.8321e-01,  3.4238e-01, -4.3152e-02,  5.8253e-03,\n",
       "        5.4965e-02,  2.3771e-01, -1.8986e-01,  8.7964e-02, -2.7330e-01,\n",
       "        5.0041e-01,  8.6523e-01,  7.0497e-01, -7.2555e-01,  1.3453e-01,\n",
       "       -4.7380e-01, -7.3388e-02, -3.4595e-01,  2.4984e-01, -1.3246e-01,\n",
       "       -5.0630e-02, -4.7013e-03,  5.8446e-02,  3.4048e-01,  6.1730e-01,\n",
       "       -5.9464e-01,  6.1018e-01, -1.9786e-01,  1.3290e-01, -1.5025e-01,\n",
       "        7.4631e-03, -3.3048e-01, -2.5657e-01, -1.4391e-01, -1.6683e-01,\n",
       "       -2.6355e-01, -3.7532e-01, -1.3298e-01, -8.5048e-01, -3.7474e-01,\n",
       "        1.3952e-01, -5.3477e-02,  7.6251e-02, -5.6403e-01, -8.9466e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_men[2].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ef7c6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15040412922563912"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1 = nlp('Sun')\n",
    "doc2 = nlp(\"notebook\")\n",
    "\n",
    "doc1.similarity(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "013a7304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly we can do this for token and span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0430b0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(vector1, vector2):\n",
    "    return np.linalg.norm(vector1 - vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c4bb91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.1864085"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "king = nlp('KING')\n",
    "queen = nlp('QUEEN')\n",
    "\n",
    "get_distance(king[0].vector, queen[0].vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "744bed3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.8034196"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "man = nlp('MAN')\n",
    "woman = nlp('WOMAN')\n",
    "\n",
    "get_distance(man[0].vector, woman[0].vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eed2e6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16c972d",
   "metadata": {},
   "source": [
    "### CUSTOM PIPELINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b461d1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline : ['CustomComponent', 'tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "from spacy import Language\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "@Language.component('CustomComponent')\n",
    "def custom_component(doc):\n",
    "    print('Doc Length: ', len(doc))\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe('CustomComponent', first=True)\n",
    "\n",
    "print('Pipeline :', nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cd1421a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc Length:  3\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Hello World!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d9adb71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat cat ANIMAL\n",
      "Golden Retriever Golden Retriever ANIMAL\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens.span import Span\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "pattern = list(nlp.pipe(['cat', 'Golden Retriever']))\n",
    "matcher.add('Animals', pattern)\n",
    "# Create more complex component using Phrase Matcher to find animals\n",
    "@Language.component('AnimalComponent')\n",
    "def animal_component(doc):\n",
    "    # create a span for match and assign the Label 'ANIMAL'\n",
    "    # overwrite doc.ents with matched spans\n",
    "    doc.ents = [Span(doc, start, end, label='ANIMAL') for match_is, start, end in matcher(doc)]\n",
    "    return doc\n",
    "\n",
    "# add the animal component to the pipeline after the ner component\n",
    "\n",
    "nlp.add_pipe('AnimalComponent', after='ner')\n",
    "\n",
    "doc = nlp('I have a cat and a Golden Retriever')\n",
    "\n",
    "#print([ent,text, ent, ent.label_] for ent in doc.ents)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97397612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
