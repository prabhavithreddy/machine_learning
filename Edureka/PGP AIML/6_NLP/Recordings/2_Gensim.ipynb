{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "513a1986",
   "metadata": {},
   "source": [
    "### Work embeddings (word vector)\n",
    "\n",
    "    Multi dimension representation of a word (multi dimension array with sparse features) created using deep learning models\n",
    "    Helps get relationships as king-queen = man - woman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca4d6fc",
   "metadata": {},
   "source": [
    "### Creating a gensim dictionary and corpus\n",
    "\n",
    "    Creating word id and corresponding frequency dictionary\n",
    "    Creating a corpus of the dictionary. A corpus (plural corpora) is a det of texts used for performing NLP tasks\n",
    "    A gensim corpus is a bit different than a normal corpus (collection of documents)\n",
    "    Gensim models can be easily saved, updated and resued\n",
    "    Our dictionary can also be updated\n",
    "    This is a more advanced and feature rich bag of words that can be used for topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feca1024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from nltk.tokenize import word_tokenize\n",
    "my_docs = [\"The movie was about spaceships and the passengers\",\n",
    "          \"I really liked the movie\",\n",
    "          \"Awesome action scenes but broing characters\",\n",
    "          \"The movie was aweful!I hate alien movies\",\n",
    "          \"Space is cool\", \"I liked the movie\",\n",
    "          \"More space films, please\",\n",
    "          \"The movie was very cool\", \"The animations were cool\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dacb4c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1)],\n",
       " [(2, 1), (5, 1), (7, 1), (8, 1), (9, 1)],\n",
       " [(10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1)],\n",
       " [(2, 1), (5, 1), (6, 1), (7, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1)],\n",
       " [(21, 1), (22, 1), (23, 1)],\n",
       " [(2, 1), (5, 1), (7, 1), (8, 1)],\n",
       " [(23, 1), (24, 1), (25, 1), (26, 1), (27, 1)],\n",
       " [(2, 1), (5, 1), (6, 1), (21, 1), (28, 1)],\n",
       " [(5, 1), (21, 1), (29, 1), (30, 1)]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_doc = [word_tokenize(doc.lower()) for doc in my_docs]\n",
    "dictionary = Dictionary(tokenized_doc)\n",
    "dictionary.token2id\n",
    "corpus=[dictionary.doc2bow(doc) for doc in tokenized_doc]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cefc1c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim corpus is a list of list where each list represents a document. \n",
    "# Also each list is a series of tuples where first item is token-id from dictionary and the 2nd \n",
    "# item is the token frequency from the document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53943cf",
   "metadata": {},
   "source": [
    "### Tf-Idf using gensim\n",
    "    * Tf-idf stands for term frequency - inverse document frequency\n",
    "    * Allows to determine the most important words in each document \n",
    "    * Idea behind tf-idf is that most corpus may have shared words beyong just stopwords and these words \n",
    "    should be downweighted in importance\n",
    "    * Ensures most common word's don't show up as keywords\n",
    "    * Keeps document specific frequent words weighted high and the common words across the entire corpus weighted low\n",
    "    \n",
    "    Tf-idf formula\n",
    "    \n",
    "        wi,j = tfi,j * log(N/dfi)\n",
    "        wi,j = tf-idf weight for token i in document j\n",
    "        tfi,j = number of occurances of token i in document j\n",
    "        dfi = number of documents that contain token i\n",
    "        N = total number of documents\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "535b320c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.19806533562037576),\n",
       " (5, 0.13662879325982816),\n",
       " (7, 0.370197258061228),\n",
       " (8, 0.5068260513210562),\n",
       " (9, 0.740394516122456)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "\n",
    "tfidf = TfidfModel(corpus)\n",
    "tfidf[corpus[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f3d53b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1)],\n",
       " [(2, 1), (5, 1), (7, 1), (8, 1), (9, 1)],\n",
       " [(10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1)],\n",
       " [(2, 1), (5, 1), (6, 1), (7, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1)],\n",
       " [(21, 1), (22, 1), (23, 1)],\n",
       " [(2, 1), (5, 1), (7, 1), (8, 1)],\n",
       " [(23, 1), (24, 1), (25, 1), (26, 1), (27, 1)],\n",
       " [(2, 1), (5, 1), (6, 1), (21, 1), (28, 1)],\n",
       " [(5, 1), (21, 1), (29, 1), (30, 1)]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01482b35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
